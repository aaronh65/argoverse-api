{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argoverse.data_loading.argoverse_forecasting_loader import ArgoverseForecastingLoader\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "from argoverse.visualization.visualize_sequences import viz_sequence\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from knn import get_multiple_forecasts_norm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/aaron/workspace/argoverse/data/forecasting_train_v1.1/train/data'\n",
    "val_dir = '/home/aaron/workspace/argoverse/data/forecasting_val_v1.1/val/data'\n",
    "test_dir = '/home/aaron/workspace/argoverse/data/forecasting_test_v1.1/test_obs/data'\n",
    "afl = ArgoverseForecastingLoader(test_dir)\n",
    "avm = ArgoverseMap()\n",
    "norm_train_trajs = np.load('norm_train_agent_trajectories.npy', allow_pickle=True)\n",
    "train_nt_dists = np.load('train_agent_nt_dists.npy', allow_pickle=True)\n",
    "test_nt_dists = np.load('test_nt_distances.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_centerlines = [None] * len(afl)\n",
    "# test_nt_dists = [None] * len(afl)\n",
    "# for idx in tqdm(range(len(afl))):\n",
    "# #for idx in range(2):\n",
    "#     centerlines, nt_dists = get_centerline_nt_attributes(afl[idx].agent_traj, afl[idx].city, avm)\n",
    "#     test_centerlines[idx] = centerlines\n",
    "#     test_nt_dists[idx] = nt_dists\n",
    "# np.save('test_centerlines.npy', test_centerlines)\n",
    "# np.save('test_nt_distances.npy', test_nt_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_all = {}\n",
    "# counter = 1\n",
    "# for idx in tqdm(range(len(afl))):\n",
    "# #for idx in range(2):\n",
    "#     agent_traj = afl[idx].agent_traj\n",
    "#     city = afl[idx].city\n",
    "#     seq_id = int(afl[idx].current_seq.name[:-4])\n",
    "#     top_k_idxs, predictions, metrics = get_multiple_forecasts_norm(agent_traj, \n",
    "#                                                                    city, \n",
    "#                                                                    norm_train_trajs, \n",
    "#                                                                    train_nt_dists, \n",
    "#                                                                    test_nt_dists[idx],\n",
    "#                                                                    is_test=True)\n",
    "#     output_all[seq_id] = predictions[:,20:,:]\n",
    "#     counter += 1\n",
    "# np.save('knn_map_test_output_all.npy', output_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from argoverse.evaluation.competition_util import generate_forecasting_h5\n",
    "\n",
    "# output_path = 'competition_files/'\n",
    "# output_all_load = np.load('knn_map_test_output_all.npy', allow_pickle=True).item()\n",
    "# output_all = dict()\n",
    "# for key, val in :\n",
    "#     output_all[key] = val\n",
    "#     print(fpath)\n",
    "#     if len(val) == 0:\n",
    "#         print('Empty prediction')\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_forecasting_h5(output_all, output_path, filename='knn_map') #this might take awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_all = np.load('knn_map_test_output_all.npy', allow_pickle=True)\n",
    "# output_all = output_all.item()\n",
    "# # avm = ArgoverseMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_map, pit_to_pkl_img = avm.get_rasterized_driveable_area('PIT')\n",
    "mia_map, mia_to_pkl_img = avm.get_rasterized_driveable_area('MIA')\n",
    "map_info = {'PIT':{'map':pit_map, 'transform':pit_to_pkl_img}, 'MIA':{'map':mia_map, 'transform':mia_to_pkl_img}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def traj_pts_outside_da(agent_traj, city_map, city_transform):\n",
    "#     traj_h = np.concatenate((agent_traj, np.ones((len(agent_traj),1))), axis=1)\n",
    "#     traj_t = np.matmul(city_transform, traj_h.T)\n",
    "#     count = 0\n",
    "#     for x,y in zip(traj_t[0], traj_t[1]):\n",
    "#         y,x = int(y),int(x)\n",
    "#         count += city_map[y][x]\n",
    "#     return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:08, 11.29it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:08, 11.30it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:00<00:08, 11.28it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:00<00:08, 11.30it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:00<00:07, 11.29it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:01<00:07, 11.25it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:01<00:07, 11.22it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:01<00:07, 11.19it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:01<00:07, 11.24it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:01<00:07, 11.23it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:01<00:06, 11.18it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:02<00:06, 11.19it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:02<00:06, 11.23it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:02<00:06, 11.26it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:02<00:06, 11.29it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:02<00:06, 11.32it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:03<00:05, 11.36it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:03<00:05, 11.37it/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:03<00:05, 11.40it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:03<00:05, 11.40it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:03<00:05, 11.31it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:03<00:04, 11.36it/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:04<00:04, 11.40it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:04<00:04, 11.42it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:04<00:04, 11.38it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:04<00:04, 11.36it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:04<00:04, 11.32it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:04<00:03, 11.32it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:05<00:03, 11.32it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:05<00:03, 11.31it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:05<00:03, 11.32it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:05<00:03, 11.35it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:05<00:03, 11.29it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:06<00:02, 11.31it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:06<00:02, 11.33it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:06<00:02, 11.33it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:06<00:02, 11.35it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:06<00:02, 11.25it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:06<00:01, 11.26it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:07<00:01, 11.33it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:07<00:01, 11.36it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:07<00:01, 11.36it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:07<00:01, 11.37it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:07<00:01, 11.27it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:07<00:00, 11.28it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:08<00:00, 11.29it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:08<00:00, 11.31it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:08<00:00, 11.45it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:08<00:00, 11.40it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.32it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# counter = 0\n",
    "# dir_fnames = os.listdir(val_dir)\n",
    "# for fname in dir_fnames:\n",
    "#     fpath = os.path.join(val_dir, f'{fname}')\n",
    "#     df = pd.read_csv(fpath)\n",
    "#     city = df[\"CITY_NAME\"].values[0]\n",
    "#     agent_x = df[df[\"OBJECT_TYPE\"]==\"AGENT\"][\"X\"]\n",
    "#     agent_y = df[df[\"OBJECT_TYPE\"]==\"AGENT\"][\"Y\"]\n",
    "#     agent_traj = np.column_stack((agent_x[:20],agent_y[:20]))\n",
    "#     city_map, city_transform = map_info[city]['map'], map_info[city]['transform']\n",
    "# #     predictions = output_all[key]\n",
    "# #     for prediction in predictions:\n",
    "# #         print(traj_pts_outside_da(prediction, city_map, city_transform))\n",
    "#     counter += 1\n",
    "#     if counter == 15: break\n",
    "        \n",
    "\n",
    "output_all = dict()\n",
    "for idx in tqdm(range(100)):\n",
    "#for idx in tqdm(range(len(afl))):\n",
    "    agent_traj = afl[idx].agent_traj\n",
    "    city = afl[idx].city\n",
    "    city_map, city_transform = map_info[city]['map'], map_info[city]['transform']\n",
    "    seq_id = int(afl[idx].current_seq.name[:-4])\n",
    "    top_k_idxs, predictions, metrics = get_multiple_forecasts_norm(agent_traj, \n",
    "                                                                   city, \n",
    "                                                                   norm_train_trajs, \n",
    "                                                                   train_nt_dists, \n",
    "                                                                   test_nt_dists[idx],\n",
    "                                                                   avm,\n",
    "                                                                   map_info,\n",
    "                                                                   abs_k=1000,\n",
    "#                                                                    plot=True,\n",
    "                                                                   is_test=True)\n",
    "    output_all[seq_id] = predictions[:,20:,:]\n",
    "#     print(predictions.shape)\n",
    "\n",
    "np.save('output_all_map_prune', output_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 244/78143 [00:40<1:51:13, 11.67it/s]"
     ]
    }
   ],
   "source": [
    "from argoverse.evaluation.competition_util import generate_forecasting_h5\n",
    "output_path = 'competition_files/'\n",
    "generate_forecasting_h5(output_all, output_path, filename='knn_map_prune') #this might take awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
